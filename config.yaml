node_dict: './ast_tree.json'
edge_dict: './ast_edge.json'
tokenizer_path: './java_tokenizer.json'

dataset:
  dataset: './BCB_dataset'
  processed_codes: './Processed_BCB_code'
  processed_graphs: './batched_graphs.pt'

  source_codes: 'data.jsonl'
  train: 'train.txt'
  valid: 'valid.txt'
  test: 'test.txt'
  # train: 'valid_dev.txt'
  # valid: 'valid_dev.txt'
  # test: 'valid_dev.txt'
  cache_dir: "./BCB_cache"

  batch_size: 8


model:
  embedding_dim: 256
  hidden_dim: 256

  num_layers: 4
  num_heads: 4

log_dir: "runs"

train:
  epochs: &epochs 10
  max_iter:  # max iteration per epoch

  optimizer:
    type: torch.optim.AdamW
    params:
      lr: 0.00005  
      betas: [0.9, 0.999]  # Mặc định của AdamW
      weight_decay: 0.0005  # Giữ nguyên weight decay

  # optimizer:
  #   type: torch.optim.SGD
  #   params:
  #     lr: 0.001
  #     momentum: 0.9
  #     weight_decay: 0.0005

  scheduler:
    type: transformers.get_linear_schedule_with_warmup
    params:
      num_warmup_steps: 
      num_training_steps: 
  amp: true

